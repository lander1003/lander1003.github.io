<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>HDR Image | Qingsen Yan</title>
    <link>/tag/hdr-image/</link>
      <atom:link href="/tag/hdr-image/index.xml" rel="self" type="application/rss+xml" />
    <description>HDR Image</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 27 Jul 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>HDR Image</title>
      <link>/tag/hdr-image/</link>
    </image>
    
    <item>
      <title>HDR Deghosting</title>
      <link>/project/ahdr/</link>
      <pubDate>Sat, 27 Jul 2019 00:00:00 +0000</pubDate>
      <guid>/project/ahdr/</guid>
      <description>&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Ghosting artifacts caused by moving objects or misalignments is a key challenge in high dynamic range (HDR) imaging for dynamic scenes. Previous methods first register the input low dynamic range (LDR) images using optical flow before merging them, which are error-prone and cause ghosts in results. A very recent work tries to bypass optical flows via a deep network with skip-connections, however, which still suffers from ghosting artifacts for severe movement. To avoid the ghosting from the source, we propose a novel attention-guided end-to-end deep neural network (AHDRNet) to produce high-quality ghost-free HDR images. Unlike previous methods directly stacking the LDR images or features for merging, we use attention modules to guide the merging according to the reference image. The attention modules automatically suppress undesired components caused by misalignments and saturation and enhance desirable fine details in the non-reference images. In addition to the attention model, we use dilated residual dense block (DRDB) to make full use of the hierarchical features and increase the receptive field for hallucinating the missing details. The proposed AHDRNet is a non-flow-based method, which can also avoid the artifacts generated by optical-flow estimation error. Experiments on different datasets show that the proposed AHDRNet can achieve state-of-the-art quantitative and qualitative results.&lt;/p&gt;
&lt;h2 id=&#34;framework&#34;&gt;Framework&lt;/h2&gt;














&lt;figure  id=&#34;figure-the-proposed-method&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;The proposed method.&#34; srcset=&#34;
               /project/ahdr/frame_hu5e8cd8f6e148936bfa0ad5c38c4f0de7_1642022_2d38363aa73328a255ea8d3d71462a72.png 400w,
               /project/ahdr/frame_hu5e8cd8f6e148936bfa0ad5c38c4f0de7_1642022_0a3b09030cda569275e393c35c45e848.png 760w,
               /project/ahdr/frame_hu5e8cd8f6e148936bfa0ad5c38c4f0de7_1642022_1200x1200_fit_lanczos_2.png 1200w&#34;
               src=&#34;/project/ahdr/frame_hu5e8cd8f6e148936bfa0ad5c38c4f0de7_1642022_2d38363aa73328a255ea8d3d71462a72.png&#34;
               width=&#34;760&#34;
               height=&#34;206&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      The proposed method.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2 id=&#34;examples-of-the-results&#34;&gt;Examples of the Results&lt;/h2&gt;














&lt;figure  id=&#34;figure-the-proposed-method-can-remove-the-ghosting-artifacts&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;The proposed method can remove the ghosting artifacts.&#34; srcset=&#34;
               /project/ahdr/fig7_hue469f6dea0857a4bd0a2a405ce591e16_3759173_f39a4729b09d7758787462fa7478a5e5.jpg 400w,
               /project/ahdr/fig7_hue469f6dea0857a4bd0a2a405ce591e16_3759173_86da09b329fe2d9d798dd914a6bb0032.jpg 760w,
               /project/ahdr/fig7_hue469f6dea0857a4bd0a2a405ce591e16_3759173_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;/project/ahdr/fig7_hue469f6dea0857a4bd0a2a405ce591e16_3759173_f39a4729b09d7758787462fa7478a5e5.jpg&#34;
               width=&#34;760&#34;
               height=&#34;502&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      The proposed method can remove the ghosting artifacts.
    &lt;/figcaption&gt;&lt;/figure&gt;














&lt;figure  id=&#34;figure-this-sample-shows-the-ahdrnet-can-handle-over-saturation-regions&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;This sample shows the AHDRNet can handle over-saturation regions.&#34; srcset=&#34;
               /project/ahdr/fig8_hu9d46132c1a717920148b945e50839526_1933687_81067cb3b85cef650de8f48a6c8d01c8.jpg 400w,
               /project/ahdr/fig8_hu9d46132c1a717920148b945e50839526_1933687_3b3c37dd2c0395ba74cff6ef669053ef.jpg 760w,
               /project/ahdr/fig8_hu9d46132c1a717920148b945e50839526_1933687_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;/project/ahdr/fig8_hu9d46132c1a717920148b945e50839526_1933687_81067cb3b85cef650de8f48a6c8d01c8.jpg&#34;
               width=&#34;760&#34;
               height=&#34;510&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      This sample shows the AHDRNet can handle over-saturation regions.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2 id=&#34;code&#34;&gt;Code&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ðŸ‘‰ &lt;a href=&#34;https://github.com/qingsenyangit/AHDRNet&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;See&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
